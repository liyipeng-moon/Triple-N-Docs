{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Triple-N Dataset Documentation","text":""},{"location":"#paper-non-human-primate-neural-responses-to-natural-scenes","title":"Paper: Non-human Primate Neural Responses to Natural Scenes","text":"<p>Contact: moonl@pku.edu.cn</p> <p>Corresponding: pbao@pku.edu.cn</p> <p>This document is currently under development to ensure clarity and ease of understanding. Your feedback is invaluable\u2014please feel free to raise an issue here or email me with any suggestions or points needing clarification.</p>"},{"location":"#news","title":"News","text":"<p>2025/10/29 \u2013 Initial creation of NNN document. Much of the content has been copied from previous materials.  2025/05/06 - Triple-N preprint online\uff01  </p>"},{"location":"Code/","title":"Code","text":""},{"location":"Code/#preprocess-code","title":"Preprocess Code","text":"<p>code for spike sorting, preprocessing LFP and generate 'GoodUnit' fils can be found here</p>"},{"location":"Code/#paper-code","title":"Paper code","text":"<p>code for analyze and generate figures in the paper can be found here</p>"},{"location":"Code/#demo-code","title":"demo code","text":"<p>Several going-through demo for illustration of our data can be found here</p> <ul> <li>demo1, generating single unit raster plot for several images</li> <li>demo2, generating populational preference of interested ROI </li> </ul>"},{"location":"Code/#behavior-control","title":"Behavior Control","text":"<p>In our experiment, fixation control and image presentation run in parallel. This is difficult to achieve with the original MonkeyLogic adapters, so we made modifications to some of the adapters. You can find our modified adapter and code here: PassiveViewing_in_ML</p>"},{"location":"MetaData/","title":"MetaData about each session","text":"<p>We have some meta-data about each session, mainly </p>"},{"location":"MetaData/#roi-definition-file-exclude_areaxls","title":"ROI Definition File: <code>exclude_area.xls</code>","text":"<p>Contains manually defined Regions of Interest (ROIs) for each session.</p> <ul> <li>One row = one ROI</li> <li>Single session may contain multiple ROIs (e.g., session 11 has object area at tip + unknown areas)</li> </ul>"},{"location":"MetaData/#file-columns","title":"File Columns","text":"Column Description Example Values <code>SesIdx</code> Session number 11, 12, 13... <code>y1</code> ROI start position (shank coordinate) 1200 (\u03bcm) <code>y2</code> ROI end position (shank coordinate) 1800 (\u03bcm) <code>arealabel</code> Area Label See full list below, with number corresponding to subject idx <code>ROIIndex</code> ROI identifier Links to 3D coordinates in another file"},{"location":"MetaData/#area-label-key","title":"Area Label Key","text":"<p>Body Face Object: - <code>MB</code>: Middle body (MSB) - <code>AB</code>: Anterior body (ASB) - <code>MF</code>: Middle face (ML) - <code>AF</code>: Anterior face (AL) - <code>MO</code>: Middle object (MLO)  - <code>MO1s1</code> and <code>MO1s2</code> correspond 2 subregions of MO1 - <code>AO</code>: Anterior object (ALO)</p> <p>Other Areas: - <code>LPP</code>: Lateral place patch - <code>PITP</code>: Posterior inferotemporal place patch - <code>CLC</code>: Central lateral color area - <code>AMC</code>: Anterior medial color area</p>"},{"location":"MetaData/#code","title":"Code","text":""},{"location":"MetaData/#script","title":"script","text":"<p>code for analyze and generate figures in the paper</p>"},{"location":"MetaData/#demo-code","title":"demo code","text":"<p>not related to paper, just a going-through demo  - demo1, generating single unit raster plot for several images  - demo2, generating populational preference of interested ROI</p>"},{"location":"MonkeyLogic/","title":"Behavioral Software","text":""},{"location":"MonkeyLogic/#monkeylogic","title":"MonkeyLogic","text":"<p>We use a matlab-based software, MonkeyLogic for behavioral control.</p>"},{"location":"ProccessedFiles/","title":"Processed Files","text":""},{"location":"ProccessedFiles/#file-structure","title":"File Structure","text":"<p>For each recording session, three file types are provided:</p>"},{"location":"ProccessedFiles/#1-goodunit-files","title":"1. GoodUnit Files","text":"<p>Contains processed spike information and some meta-data.</p> <p>Example Filename: <code>GoodUnit_240629_JianJian_NSD1000_LOC_g2.mat</code></p>"},{"location":"ProccessedFiles/#key-file-contents","title":"Key File Contents","text":"Component Description <code>global_params.pre_onset</code> Time (ms) prior to stimuli onset (here: 50) <code>global_params.post_onset</code> Time (ms) after stimuli onset (here: 400) <code>global_params.PsthRange</code> Time points  for raster and PSTH below  Here: -50:1:400 <code>meta_data</code> Recording metadata and processed behavior <code>meta_data.trial_valid_idx</code> Stimuli indices for each trial  - 0: failed trial - 1-1000: NSD Shared 1000  - 1001-1072: Localizer stimuli <code>GoodUnitStrc</code> Organized sturcture for each units"},{"location":"ProccessedFiles/#goodunitstrc-structure-key-field","title":"GoodUnitStrc Structure Key Field","text":"Field Format Description <code>Raster</code> [trial_idx \u00d7 time_point] Spike raster matrix  typically 0 1, where 1 is one spike  could be 2 or lager for some MUA <code>response_matrix_img</code> [image_idx \u00d7 time_point] PSTH matrix with a 20ms box bin <code>qm</code> [1 \u00d7 n_metric] Quality metric from BombCell <code>spiketime_ms</code> [1 \u00d7 n_spikes] Spike train time point relative to stimuli train <code>waveform</code> [n Chan \u00d7 61 Sample] Spike waveform <p>note: <code>trial_idx</code> here correspond to all valid trials (i.e. <code>meta_data.trial_valid_idx(meta_data.trial_valid_idx~=0)</code>)</p>"},{"location":"ProccessedFiles/#2-h5-files","title":"2. H5 Files","text":"<p>Better format for faster data access relative to matlab GoodUnitStrc. Fetch with matlab:</p> <pre><code>    h5read('xxx', '/field')\n</code></pre> <p>Example Filename: <code>ses01_240629_M1_2.h5</code></p>"},{"location":"ProccessedFiles/#contents","title":"Contents","text":"Field Format Description <code>raster_matrix_img</code> [unit_num \u00d7 trial_idx \u00d7 time_point] Same as GoodUnitStrc <code>response_matrix_img</code> [unit_num \u00d7 image_idx \u00d7 time_point] Same as GoodUnitStrc"},{"location":"ProccessedFiles/#3-processed-files","title":"3. Processed Files","text":"<p>Contains unit-wise processed information.</p> <p>Example Filename: <code>Processed_ses01_240629_M1_2.mat</code></p>"},{"location":"ProccessedFiles/#key-variables","title":"Key Variables","text":"Variable Format Description <code>B_SI</code>, <code>F_SI</code>, <code>O_SI</code> [1 \u00d7 unit_num] d-prime for body, face, object categories from localizer <code>best_t_time</code> [1 \u00d7 unit_num] Time window with highest reliability <code>mean_psth</code> [unit_num \u00d7 time_point] Averaged PSTH across images <code>pos</code> [1 \u00d7 unit_num] Spike position along the Electrode shank <code>reliability_basic/best</code> [1 \u00d7 unit_num] Split-half reliability  - basic: calculated from fixed time window  - best: calculated from best time window <code>response_basic/best</code> [unit_num \u00d7 1072] Averaged firing rates   - basic: calculated from fixed time window  - best: calculated from best time window <code>snr</code>, <code>snr_max</code> [1 \u00d7 unit_num] Signal-to-noise ratios  - max: calculated by most preferred stimuli <code>UnitType</code> [1 \u00d7 unit_num] Unit type from BombCell: 1: Single Unit2: MUA3-4: Non-somatic"},{"location":"RawData/","title":"Raw Data Structure and Preprocessing","text":"<p>The raw data are saved at <code>'xxx'</code>, with each session organized by recording day and session index(if one day with multiple sessions). Within each session folder, there are:</p> <ul> <li>kilosort_def_5block_97 \u2013 Contains the output of Kilosort 4  </li> <li>LFPprep \u2013 Contains the preprocessed LFP signals  </li> <li>NPX_XXDDDDDD\u2026 \u2013 <code>XX</code> corresponds to the subject name, and <code>DDDDDD</code> corresponds to the recording day  </li> <li>processed \u2013 Contains processed data and converted files  </li> <li>One <code>.bhv</code> file \u2013 Recorded with MonkeyLogic (ML) software</li> </ul>"},{"location":"RawData/#npx_-folder-contents","title":"NPX_ folder contents","text":"<p>The <code>NPX_</code> folder, recorded with SpikeGLX, contains multiple files organized into three streams. Each stream includes a <code>.bin</code> file and its corresponding <code>.meta</code> file, which stores metadata such as sampling rate and gain.  </p> <ul> <li>Streams:</li> <li>ap \u2013 Active potential (spike) data  </li> <li>lf \u2013 Local field potential (LFP) data  </li> <li>ni \u2013 Additional task-related inputs (named <code>ni</code> because the data are recorded via a National Instruments card), such as event codes sent from the stimulus computer to the electrophysiology computer, and analog input from the photodiode.</li> </ul>"},{"location":"RawData/#bhv-file","title":".bhv file","text":"<ul> <li>Recorded with MonkeyLogic (ML) software  </li> <li>Can be loaded using the <code>mlread</code> function provided by ML, for convenience, a converted <code>.mat</code> version is also provided in the <code>processed</code> folder</li> </ul>"},{"location":"RawData/#processed","title":"processed","text":"<ul> <li>Within each processed folder, there are:</li> </ul>"},{"location":"howtogetdata/","title":"Triple-N Dataset Documentation","text":"<p>Our raw data are saved at s3:...</p>"}]}